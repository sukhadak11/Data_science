{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91293d02-47bc-4124-af24-61c283a0c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb008ff7-6f1f-49b4-b43d-3f43b0b37d94",
   "metadata": {},
   "source": [
    "The Sequence-to-Sequence (Seq2Seq) model is a type of neural network architecture widely used in machine learning for tasks that involve mapping one sequence of data to another. It processes an input sequence and generates a corresponding output sequence. Seq2Seq models have had a significant impact in areas such as natural language processing (NLP), machine translation, speech recognition and time-series prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6341349e-b4a7-461f-a0c2-002f03d21e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c879526-bb3e-4584-8fb6-ce43f0bdbe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        prediction = self.fc(output.squeeze(0))\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0942ee07-e982-4829-9b68-30e2c25a7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg=None, max_len=10, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[1]\n",
    "        trg_vocab_size = self.decoder.fc.out_features\n",
    "        outputs = []\n",
    "\n",
    "        hidden = self.encoder(src)\n",
    "\n",
    "        input = torch.zeros(batch_size, dtype=torch.long).to(self.device)\n",
    "\n",
    "        for t in range(max_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            top1 = output.argmax(1)\n",
    "            outputs.append(top1.unsqueeze(0))\n",
    "\n",
    "            if trg is not None and t < trg.shape[0] and torch.rand(1).item() < teacher_forcing_ratio:\n",
    "                input = trg[t]\n",
    "            else:\n",
    "                input = top1\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=0)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bae5dc-b5cd-43c5-9d44-d6544f93dacf",
   "metadata": {},
   "source": [
    "- Batch size & vocab size: extracted from input and decoder.\n",
    "\n",
    "- Encoding: input sequence → encoder → context vector (hidden).\n",
    "- Start token: initialize decoder with token 0.\n",
    "- Loop over max_len:\n",
    "- Decoder predicts next token.\n",
    "- top1 → token with max probability.\n",
    "- Append top1 to outputs.\n",
    "- Teacher forcing: sometimes feed true target token instead of prediction.\n",
    "- Return predictions: concatenated sequence of token IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b429ae73-a7fc-4381-9ce7-d15f6ff28577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sequence (input tokens):\n",
      "tensor([[1, 3, 4, 6, 3],\n",
      "        [2, 1, 1, 7, 2]])\n",
      "\n",
      "Target sequence (true tokens):\n",
      "tensor([[8, 1, 1, 9, 3],\n",
      "        [5, 2, 1, 3, 3]])\n",
      "\n",
      "Predicted sequence (model output tokens):\n",
      "tensor([[3, 4, 6, 6, 4],\n",
      "        [3, 3, 3, 3, 3]])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "VOCAB_SIZE = 10\n",
    "EMB_DIM = 8\n",
    "HID_DIM = 16\n",
    "SEQ_LEN = 5\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "enc = Encoder(VOCAB_SIZE, EMB_DIM, HID_DIM)\n",
    "dec = Decoder(VOCAB_SIZE, EMB_DIM, HID_DIM)\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "src = torch.randint(1, VOCAB_SIZE, (SEQ_LEN, BATCH_SIZE)).to(device)\n",
    "trg = torch.randint(1, VOCAB_SIZE, (SEQ_LEN, BATCH_SIZE)).to(device)\n",
    "\n",
    "outputs = model(src, trg, max_len=SEQ_LEN, teacher_forcing_ratio=0.7)\n",
    "\n",
    "print(\"Source sequence (input tokens):\")\n",
    "print(src.T)\n",
    "print(\"\\nTarget sequence (true tokens):\")\n",
    "print(trg.T)\n",
    "print(\"\\nPredicted sequence (model output tokens):\")\n",
    "print(outputs.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e76c7a-451b-495c-b0c2-c6ce282e0338",
   "metadata": {},
   "source": [
    "# Applications\n",
    "\n",
    "- Machine Translation: Converts text between languages like English to French.\n",
    "- Text Summarization: Produces concise summaries of documents or news articles.\n",
    "- Speech Recognition: Transcribes spoken language into text.\n",
    "- Image Captioning: Generates captions for images by combining visual features with sequence generation.\n",
    "- Time-Series Prediction: Predicts future sequences based on past temporal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e2c9ea-196f-43d4-9b0f-f57553927d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
